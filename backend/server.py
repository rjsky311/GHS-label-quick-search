from fastapi import FastAPI, APIRouter, HTTPException
from fastapi.responses import StreamingResponse
from dotenv import load_dotenv
from starlette.middleware.cors import CORSMiddleware
import os
import logging
from pathlib import Path
from pydantic import BaseModel, Field, ConfigDict
from typing import List, Optional, Dict, Any
import uuid
from datetime import datetime, timezone
import httpx
import asyncio
from io import BytesIO
from openpyxl import Workbook
from openpyxl.styles import Font, Alignment, PatternFill, Border, Side
import csv
import re

# Import expanded chemical dictionaries (1707 CAS entries, 1816 English entries)
from chemical_dict import CAS_TO_ZH, CAS_TO_EN, CHEMICAL_NAMES_ZH_EXPANDED

ROOT_DIR = Path(__file__).parent
load_dotenv(ROOT_DIR / '.env')

# MongoDB connection (optional - for future features)
mongo_url = os.environ.get('MONGO_URL', '')
db = None
client = None

if mongo_url:
    try:
        from motor.motor_asyncio import AsyncIOMotorClient
        client = AsyncIOMotorClient(mongo_url)
        db = client[os.environ.get('DB_NAME', 'ghs_db')]
        logging.info("MongoDB connected successfully")
    except Exception as e:
        logging.warning(f"MongoDB connection failed: {e}. Running without database.")
else:
    logging.info("No MONGO_URL provided. Running without database.")

# Create the main app without a prefix
app = FastAPI(title="GHS Label Quick Search API")

# Create a router with the /api prefix
api_router = APIRouter(prefix="/api")

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Common chemical names Chinese translation dictionary
CHEMICAL_NAMES_ZH = {
    # å¸¸è¦‹æº¶åŠ‘
    "ethanol": "ä¹™é†‡",
    "methanol": "ç”²é†‡",
    "water": "æ°´",
    "acetone": "ä¸™é…®",
    "isopropanol": "ç•°ä¸™é†‡",
    "2-propanol": "ç•°ä¸™é†‡",
    "ethyl acetate": "ä¹™é…¸ä¹™é…¯",
    "dichloromethane": "äºŒæ°¯ç”²çƒ·",
    "chloroform": "æ°¯ä»¿",
    "toluene": "ç”²è‹¯",
    "benzene": "è‹¯",
    "hexane": "å·±çƒ·",
    "diethyl ether": "ä¹™é†š",
    "tetrahydrofuran": "å››æ°«å‘‹å–ƒ",
    "dimethyl sulfoxide": "äºŒç”²åŸºäºžç¢¸",
    "dmso": "äºŒç”²åŸºäºžç¢¸",
    "dimethylformamide": "äºŒç”²åŸºç”²é†¯èƒº",
    "dmf": "äºŒç”²åŸºç”²é†¯èƒº",
    "acetonitrile": "ä¹™è…ˆ",
    "pyridine": "å¡å•¶",
    "triethylamine": "ä¸‰ä¹™èƒº",
    
    # å¸¸è¦‹é…¸é¹¼
    "hydrochloric acid": "é¹½é…¸",
    "sulfuric acid": "ç¡«é…¸",
    "nitric acid": "ç¡é…¸",
    "acetic acid": "ä¹™é…¸",
    "phosphoric acid": "ç£·é…¸",
    "sodium hydroxide": "æ°«æ°§åŒ–éˆ‰",
    "potassium hydroxide": "æ°«æ°§åŒ–é‰€",
    "ammonia": "æ°¨",
    "ammonium hydroxide": "æ°¨æ°´",
    
    # å¸¸è¦‹åŒ–å­¸å“
    "sodium chloride": "æ°¯åŒ–éˆ‰",
    "potassium chloride": "æ°¯åŒ–é‰€",
    "calcium chloride": "æ°¯åŒ–éˆ£",
    "magnesium sulfate": "ç¡«é…¸éŽ‚",
    "sodium carbonate": "ç¢³é…¸éˆ‰",
    "sodium bicarbonate": "ç¢³é…¸æ°«éˆ‰",
    "hydrogen peroxide": "éŽæ°§åŒ–æ°«",
    "formaldehyde": "ç”²é†›",
    "glutaraldehyde": "æˆŠäºŒé†›",
    "phenol": "è‹¯é…š",
    "aniline": "è‹¯èƒº",
    "nitrobenzene": "ç¡åŸºè‹¯",
    "chlorobenzene": "æ°¯è‹¯",
    "bromobenzene": "æº´è‹¯",
    "iodobenzene": "ç¢˜è‹¯",
    "benzoic acid": "è‹¯ç”²é…¸",
    "benzaldehyde": "è‹¯ç”²é†›",
    "benzyl alcohol": "è‹„é†‡",
    "styrene": "è‹¯ä¹™çƒ¯",
    "naphthalene": "è˜",
    "anthracene": "è’½",
    "anthraquinone": "è’½é†Œ",
    "xylene": "äºŒç”²è‹¯",
    
    # é‡‘å±¬èˆ‡åŒ–åˆç‰©
    "mercury": "æ±ž",
    "lead": "é‰›",
    "arsenic": "ç ·",
    "cadmium": "éŽ˜",
    "chromium": "é‰»",
    "nickel": "éŽ³",
    "copper sulfate": "ç¡«é…¸éŠ…",
    "silver nitrate": "ç¡é…¸éŠ€",
    "zinc chloride": "æ°¯åŒ–é‹…",
    "iron(iii) chloride": "æ°¯åŒ–éµ",
    "ferric chloride": "æ°¯åŒ–éµ",
    
    # æœ‰æ©ŸåŒ–åˆç‰©
    "glucose": "è‘¡è„ç³–",
    "sucrose": "è”—ç³–",
    "fructose": "æžœç³–",
    "glycerol": "ç”˜æ²¹",
    "urea": "å°¿ç´ ",
    "citric acid": "æª¸æª¬é…¸",
    "oxalic acid": "è‰é…¸",
    "tartaric acid": "é…’çŸ³é…¸",
    "lactic acid": "ä¹³é…¸",
    "formic acid": "ç”²é…¸",
    "propionic acid": "ä¸™é…¸",
    "butyric acid": "ä¸é…¸",
    
    # èƒºé¡ž
    "methylamine": "ç”²èƒº",
    "dimethylamine": "äºŒç”²èƒº",
    "trimethylamine": "ä¸‰ç”²èƒº",
    "ethylamine": "ä¹™èƒº",
    "diethylamine": "äºŒä¹™èƒº",
    "aniline": "è‹¯èƒº",
    "4-bromoaniline": "4-æº´è‹¯èƒº",
    "3-aminopyridine": "3-æ°¨åŸºå¡å•¶",
    
    # é†›é¡ž
    "formaldehyde": "ç”²é†›",
    "acetaldehyde": "ä¹™é†›",
    "propionaldehyde": "ä¸™é†›",
    "butyraldehyde": "ä¸é†›",
    "benzaldehyde": "è‹¯ç”²é†›",
    
    # é…®é¡ž
    "acetone": "ä¸™é…®",
    "methyl ethyl ketone": "ä¸é…®",
    "cyclohexanone": "ç’°å·±é…®",
    "acetophenone": "è‹¯ä¹™é…®",
    
    # ç¡¼åŒ–åˆç‰©
    "boric acid": "ç¡¼é…¸",
    "sodium borate": "ç¡¼ç ‚",
    "bis(pinacolato)diboron": "é›™(é »é‚£é†‡)äºŒç¡¼",
    "bis(pinacolato)diborane": "é›™(é »é‚£é†‡ç¡¼é…¸)äºŒç¡¼çƒ·",
    
    # é¹µåŒ–ç‰©
    "bromine": "æº´",
    "iodine": "ç¢˜",
    "chlorine": "æ°¯",
    "fluorine": "æ°Ÿ",
    "carbon tetrachloride": "å››æ°¯åŒ–ç¢³",
    "chloroform": "æ°¯ä»¿",
    "methyl iodide": "ç¢˜ç”²çƒ·",
    "methyl bromide": "æº´ç”²çƒ·",
    "ethyl bromide": "æº´ä¹™çƒ·",
    
    # æ°ŸåŒ–ç‰©
    "hydrofluoric acid": "æ°«æ°Ÿé…¸",
    "sodium fluoride": "æ°ŸåŒ–éˆ‰",
    "potassium fluoride": "æ°ŸåŒ–é‰€",
    
    # æ°°åŒ–ç‰©
    "hydrogen cyanide": "æ°°åŒ–æ°«",
    "sodium cyanide": "æ°°åŒ–éˆ‰",
    "potassium cyanide": "æ°°åŒ–é‰€",
    "benzonitrile": "è‹¯ç”²è…ˆ",
    "acetonitrile": "ä¹™è…ˆ",
    
    # å…¶ä»–å¸¸è¦‹åŒ–å­¸å“
    "silica gel": "çŸ½è† ",
    "activated carbon": "æ´»æ€§ç‚­",
    "sodium sulfate": "ç¡«é…¸éˆ‰",
    "magnesium chloride": "æ°¯åŒ–éŽ‚",
    "potassium permanganate": "é«˜éŒ³é…¸é‰€",
    "sodium hypochlorite": "æ¬¡æ°¯é…¸éˆ‰",
    "calcium hypochlorite": "æ¬¡æ°¯é…¸éˆ£",
}

# GHS Pictogram mapping
GHS_PICTOGRAMS = {
    "GHS01": {"name": "Explosive", "name_zh": "çˆ†ç‚¸ç‰©", "icon": "ðŸ’¥", "image": "https://pubchem.ncbi.nlm.nih.gov/images/ghs/GHS01.svg"},
    "GHS02": {"name": "Flammable", "name_zh": "æ˜“ç‡ƒç‰©", "icon": "ðŸ”¥", "image": "https://pubchem.ncbi.nlm.nih.gov/images/ghs/GHS02.svg"},
    "GHS03": {"name": "Oxidizer", "name_zh": "æ°§åŒ–åŠ‘", "icon": "â­•", "image": "https://pubchem.ncbi.nlm.nih.gov/images/ghs/GHS03.svg"},
    "GHS04": {"name": "Compressed Gas", "name_zh": "å£“ç¸®æ°£é«”", "icon": "ðŸ«§", "image": "https://pubchem.ncbi.nlm.nih.gov/images/ghs/GHS04.svg"},
    "GHS05": {"name": "Corrosive", "name_zh": "è…è•æ€§", "icon": "ðŸ§ª", "image": "https://pubchem.ncbi.nlm.nih.gov/images/ghs/GHS05.svg"},
    "GHS06": {"name": "Toxic", "name_zh": "åŠ‡æ¯’", "icon": "ðŸ’€", "image": "https://pubchem.ncbi.nlm.nih.gov/images/ghs/GHS06.svg"},
    "GHS07": {"name": "Irritant", "name_zh": "åˆºæ¿€æ€§/æœ‰å®³", "icon": "âš ï¸", "image": "https://pubchem.ncbi.nlm.nih.gov/images/ghs/GHS07.svg"},
    "GHS08": {"name": "Health Hazard", "name_zh": "å¥åº·å±å®³", "icon": "ðŸ«", "image": "https://pubchem.ncbi.nlm.nih.gov/images/ghs/GHS08.svg"},
    "GHS09": {"name": "Environmental Hazard", "name_zh": "ç’°å¢ƒå±å®³", "icon": "ðŸŸ", "image": "https://pubchem.ncbi.nlm.nih.gov/images/ghs/GHS09.svg"},
}

# H-code Chinese translations
H_CODE_TRANSLATIONS = {
    "H200": "ä¸ç©©å®šçˆ†ç‚¸ç‰©",
    "H201": "çˆ†ç‚¸ç‰©ï¼›æ•´é«”çˆ†ç‚¸å±éšª",
    "H202": "çˆ†ç‚¸ç‰©ï¼›åš´é‡æ‹‹å°„å±éšª",
    "H203": "çˆ†ç‚¸ç‰©ï¼›ç«ç½ã€çˆ†ç‚¸æˆ–æ‹‹å°„å±éšª",
    "H204": "ç«ç½æˆ–æ‹‹å°„å±éšª",
    "H205": "é‡ç«å¯èƒ½æ•´é«”çˆ†ç‚¸",
    "H220": "æ¥µæ˜“ç‡ƒæ°£é«”",
    "H221": "æ˜“ç‡ƒæ°£é«”",
    "H222": "æ¥µæ˜“ç‡ƒæ°£æº¶è† ",
    "H223": "æ˜“ç‡ƒæ°£æº¶è† ",
    "H224": "æ¥µæ˜“ç‡ƒæ¶²é«”å’Œè’¸æ°£",
    "H225": "é«˜åº¦æ˜“ç‡ƒæ¶²é«”å’Œè’¸æ°£",
    "H226": "æ˜“ç‡ƒæ¶²é«”å’Œè’¸æ°£",
    "H227": "å¯ç‡ƒæ¶²é«”",
    "H228": "æ˜“ç‡ƒå›ºé«”",
    "H229": "å£“åŠ›å®¹å™¨ï¼šé‡ç†±å¯èƒ½çˆ†è£‚",
    "H230": "å¯èƒ½ä»¥çˆ†ç‚¸æ–¹å¼åæ‡‰ï¼Œå³ä½¿æ²’æœ‰ç©ºæ°£",
    "H231": "åœ¨é«˜å£“/é«˜æº«ä¸‹å¯èƒ½ä»¥çˆ†ç‚¸æ–¹å¼åæ‡‰ï¼Œå³ä½¿æ²’æœ‰ç©ºæ°£",
    "H240": "é‡ç†±å¯èƒ½çˆ†ç‚¸",
    "H241": "é‡ç†±å¯èƒ½èµ·ç«æˆ–çˆ†ç‚¸",
    "H242": "é‡ç†±å¯èƒ½èµ·ç«",
    "H250": "æš´éœ²åœ¨ç©ºæ°£ä¸­æœƒè‡ªç‡ƒ",
    "H251": "è‡ªç†±ï¼›å¯èƒ½èµ·ç«",
    "H252": "å¤§é‡å †ç©æ™‚è‡ªç†±ï¼›å¯èƒ½èµ·ç«",
    "H260": "é‡æ°´æ”¾å‡ºæ˜“ç‡ƒæ°£é«”ï¼Œå¯èƒ½è‡ªç‡ƒ",
    "H261": "é‡æ°´æ”¾å‡ºæ˜“ç‡ƒæ°£é«”",
    "H270": "å¯èƒ½å°Žè‡´æˆ–åŠ åŠ‡ç‡ƒç‡’ï¼›æ°§åŒ–åŠ‘",
    "H271": "å¯èƒ½å¼•èµ·ç‡ƒç‡’æˆ–çˆ†ç‚¸ï¼›å¼·æ°§åŒ–åŠ‘",
    "H272": "å¯èƒ½åŠ åŠ‡ç‡ƒç‡’ï¼›æ°§åŒ–åŠ‘",
    "H280": "å…§å«é«˜å£“æ°£é«”ï¼›é‡ç†±å¯èƒ½çˆ†ç‚¸",
    "H281": "å…§å«å†·å‡æ°£é«”ï¼›å¯èƒ½é€ æˆä½Žæº«ç¼å‚·",
    "H290": "å¯èƒ½è…è•é‡‘å±¬",
    "H300": "åžé£Ÿè‡´å‘½",
    "H301": "åžé£Ÿæœ‰æ¯’",
    "H302": "åžé£Ÿæœ‰å®³",
    "H303": "åžé£Ÿå¯èƒ½æœ‰å®³",
    "H304": "åžé£Ÿä¸¦é€²å…¥å‘¼å¸é“å¯èƒ½è‡´å‘½",
    "H305": "åžé£Ÿä¸¦é€²å…¥å‘¼å¸é“å¯èƒ½æœ‰å®³",
    "H310": "çš®è†šæŽ¥è§¸è‡´å‘½",
    "H311": "çš®è†šæŽ¥è§¸æœ‰æ¯’",
    "H312": "çš®è†šæŽ¥è§¸æœ‰å®³",
    "H313": "çš®è†šæŽ¥è§¸å¯èƒ½æœ‰å®³",
    "H314": "é€ æˆåš´é‡çš®è†šç¼å‚·å’Œçœ¼ç›æå‚·",
    "H315": "é€ æˆçš®è†šåˆºæ¿€",
    "H316": "é€ æˆè¼•å¾®çš®è†šåˆºæ¿€",
    "H317": "å¯èƒ½é€ æˆçš®è†šéŽæ•åæ‡‰",
    "H318": "é€ æˆåš´é‡çœ¼ç›æå‚·",
    "H319": "é€ æˆåš´é‡çœ¼ç›åˆºæ¿€",
    "H320": "é€ æˆçœ¼ç›åˆºæ¿€",
    "H330": "å¸å…¥è‡´å‘½",
    "H331": "å¸å…¥æœ‰æ¯’",
    "H332": "å¸å…¥æœ‰å®³",
    "H333": "å¸å…¥å¯èƒ½æœ‰å®³",
    "H334": "å¸å…¥å¯èƒ½å°Žè‡´éŽæ•æˆ–å“®å–˜ç—‡ç‹€æˆ–å‘¼å¸å›°é›£",
    "H335": "å¯èƒ½é€ æˆå‘¼å¸é“åˆºæ¿€",
    "H336": "å¯èƒ½é€ æˆæ˜ç¡æˆ–é ­æšˆ",
    "H340": "å¯èƒ½å°Žè‡´éºå‚³æ€§ç¼ºé™·",
    "H341": "æ‡·ç–‘æœƒå°Žè‡´éºå‚³æ€§ç¼ºé™·",
    "H350": "å¯èƒ½è‡´ç™Œ",
    "H351": "æ‡·ç–‘æœƒè‡´ç™Œ",
    "H360": "å¯èƒ½æå®³ç”Ÿè‚²èƒ½åŠ›æˆ–èƒŽå…’",
    "H361": "æ‡·ç–‘æœƒæå®³ç”Ÿè‚²èƒ½åŠ›æˆ–èƒŽå…’",
    "H362": "å¯èƒ½å°å“ºä¹³å…’ç«¥é€ æˆå‚·å®³",
    "H370": "æœƒå°å™¨å®˜é€ æˆæå®³",
    "H371": "å¯èƒ½æœƒå°å™¨å®˜é€ æˆæå®³",
    "H372": "é•·æœŸæˆ–åè¦†æš´éœ²æœƒå°å™¨å®˜é€ æˆæå®³",
    "H373": "é•·æœŸæˆ–åè¦†æš´éœ²å¯èƒ½æœƒå°å™¨å®˜é€ æˆæå®³",
    "H400": "å°æ°´ç”Ÿç”Ÿç‰©æ¯’æ€§éžå¸¸å¤§",
    "H401": "å°æ°´ç”Ÿç”Ÿç‰©æœ‰æ¯’",
    "H402": "å°æ°´ç”Ÿç”Ÿç‰©æœ‰å®³",
    "H410": "å°æ°´ç”Ÿç”Ÿç‰©æ¯’æ€§éžå¸¸å¤§ä¸¦å…·æœ‰é•·æœŸæŒçºŒå½±éŸ¿",
    "H411": "å°æ°´ç”Ÿç”Ÿç‰©æœ‰æ¯’ä¸¦å…·æœ‰é•·æœŸæŒçºŒå½±éŸ¿",
    "H412": "å°æ°´ç”Ÿç”Ÿç‰©æœ‰å®³ä¸¦å…·æœ‰é•·æœŸæŒçºŒå½±éŸ¿",
    "H413": "å¯èƒ½å°æ°´ç”Ÿç”Ÿç‰©é€ æˆé•·æœŸæŒçºŒæœ‰å®³å½±éŸ¿",
    "H420": "ç ´å£žé«˜å±¤å¤§æ°£ä¸­çš„è‡­æ°§ï¼Œå±å®³å…¬çœ¾å¥åº·å’Œç’°å¢ƒ",
}

# Define Models
class CASQuery(BaseModel):
    cas_numbers: List[str]

class GHSReport(BaseModel):
    """Single GHS classification report"""
    pictograms: List[Dict[str, Any]] = []
    hazard_statements: List[Dict[str, str]] = []
    signal_word: Optional[str] = None
    signal_word_zh: Optional[str] = None
    source: Optional[str] = None
    report_count: Optional[str] = None

class ChemicalResult(BaseModel):
    cas_number: str
    cid: Optional[int] = None
    name_en: Optional[str] = None
    name_zh: Optional[str] = None
    # Primary (main) classification - first/most reported
    ghs_pictograms: List[Dict[str, Any]] = []
    hazard_statements: List[Dict[str, str]] = []
    signal_word: Optional[str] = None
    signal_word_zh: Optional[str] = None
    # Other classification reports
    other_classifications: List[GHSReport] = []
    has_multiple_classifications: bool = False
    found: bool = False
    error: Optional[str] = None

class ExportRequest(BaseModel):
    results: List[Dict[str, Any]]
    format: str = "xlsx"  # xlsx or csv

# Helper functions
def normalize_cas(cas: str) -> str:
    """Normalize CAS number format"""
    cas = cas.strip()
    # Remove common prefixes
    cas = re.sub(r'^CAS[:\s-]*', '', cas, flags=re.IGNORECASE)
    # Keep only digits and hyphens
    cas = re.sub(r'[^\d-]', '', cas)
    
    # Try to fix common format issues
    if cas:
        parts = cas.split('-')
        if len(parts) == 3:
            # Remove leading zeros from first part
            parts[0] = parts[0].lstrip('0') or '0'
            # Remove leading zeros from last part (check digit should be single digit)
            parts[2] = parts[2].lstrip('0') or '0'
            # Ensure middle part has 2 digits
            if len(parts[1]) == 1:
                parts[1] = '0' + parts[1]
            cas = '-'.join(parts)
        elif len(parts) == 1 and len(cas) >= 5:
            # Try to parse CAS without hyphens (e.g., 6417-5 or 64175)
            digits = re.sub(r'[^0-9]', '', cas)
            if len(digits) >= 5:
                # CAS format: XXXXXX-XX-X
                check = digits[-1]
                middle = digits[-3:-1]
                first = digits[:-3].lstrip('0') or '0'
                cas = f"{first}-{middle}-{check}"
    
    return cas

def extract_ghs_pictograms(ghs_data: dict) -> List[Dict[str, Any]]:
    """Extract GHS pictogram codes from PubChem data - DEPRECATED, use extract_all_ghs_classifications"""
    pictograms = []
    seen_codes = set()
    try:
        sections = ghs_data.get("Record", {}).get("Section", [])
        for section in sections:
            if section.get("TOCHeading") == "Safety and Hazards":
                for subsection in section.get("Section", []):
                    if subsection.get("TOCHeading") == "Hazards Identification":
                        for subsubsection in subsection.get("Section", []):
                            if subsubsection.get("TOCHeading") == "GHS Classification":
                                for info in subsubsection.get("Information", []):
                                    if info.get("Name") == "Pictogram(s)":
                                        for markup in info.get("Value", {}).get("StringWithMarkup", []):
                                            for extra in markup.get("Markup", []):
                                                if extra.get("Type") == "Icon":
                                                    url = extra.get("URL", "")
                                                    match = re.search(r'(GHS\d{2})', url)
                                                    if match:
                                                        pic_code = match.group(1)
                                                        if pic_code in GHS_PICTOGRAMS and pic_code not in seen_codes:
                                                            seen_codes.add(pic_code)
                                                            pictograms.append({
                                                                "code": pic_code,
                                                                **GHS_PICTOGRAMS[pic_code]
                                                            })
    except Exception as e:
        logger.error(f"Error extracting pictograms: {e}")
    return pictograms

def extract_all_ghs_classifications(ghs_data: dict) -> List[Dict[str, Any]]:
    """
    Extract ALL GHS classification reports from PubChem data.
    Returns a list of classification reports, each containing pictograms, hazards, signal word, and source.
    The first report is typically the primary/most common classification.
    """
    reports = []
    
    try:
        sections = ghs_data.get("Record", {}).get("Section", [])
        for section in sections:
            if section.get("TOCHeading") == "Safety and Hazards":
                for subsection in section.get("Section", []):
                    if subsection.get("TOCHeading") == "Hazards Identification":
                        for subsubsection in subsection.get("Section", []):
                            if subsubsection.get("TOCHeading") == "GHS Classification":
                                # Parse each report entry
                                current_report = None
                                
                                for info in subsubsection.get("Information", []):
                                    info_name = info.get("Name", "")
                                    
                                    if info_name == "Pictogram(s)":
                                        # Start a new report when we encounter Pictogram(s)
                                        if current_report is not None:
                                            reports.append(current_report)
                                        
                                        current_report = {
                                            "pictograms": [],
                                            "hazard_statements": [],
                                            "signal_word": None,
                                            "signal_word_zh": None,
                                            "source": None,
                                            "report_count": None
                                        }
                                        
                                        # Extract pictogram codes
                                        seen_codes = set()
                                        for markup in info.get("Value", {}).get("StringWithMarkup", []):
                                            for extra in markup.get("Markup", []):
                                                if extra.get("Type") == "Icon":
                                                    url = extra.get("URL", "")
                                                    match = re.search(r'(GHS\d{2})', url)
                                                    if match:
                                                        pic_code = match.group(1)
                                                        if pic_code in GHS_PICTOGRAMS and pic_code not in seen_codes:
                                                            seen_codes.add(pic_code)
                                                            current_report["pictograms"].append({
                                                                "code": pic_code,
                                                                **GHS_PICTOGRAMS[pic_code]
                                                            })
                                    
                                    elif info_name == "Signal" and current_report is not None:
                                        signal_translations = {"Danger": "å±éšª", "Warning": "è­¦å‘Š"}
                                        for markup in info.get("Value", {}).get("StringWithMarkup", []):
                                            signal = markup.get("String", "")
                                            if signal:
                                                current_report["signal_word"] = signal
                                                current_report["signal_word_zh"] = signal_translations.get(signal, signal)
                                                break
                                    
                                    elif info_name == "GHS Hazard Statements" and current_report is not None:
                                        seen_codes = set()
                                        for markup in info.get("Value", {}).get("StringWithMarkup", []):
                                            text = markup.get("String", "")
                                            h_match = re.search(r'(H\d{3})', text)
                                            if h_match:
                                                h_code = h_match.group(1)
                                                if h_code not in seen_codes:
                                                    seen_codes.add(h_code)
                                                    zh_text = H_CODE_TRANSLATIONS.get(h_code, "")
                                                    current_report["hazard_statements"].append({
                                                        "code": h_code,
                                                        "text_en": text,
                                                        "text_zh": zh_text if zh_text else text
                                                    })
                                    
                                    elif info_name == "ECHA C&L Notifications Summary" and current_report is not None:
                                        for markup in info.get("Value", {}).get("StringWithMarkup", []):
                                            text = markup.get("String", "")
                                            if text:
                                                current_report["source"] = text
                                                # Extract report count if available
                                                count_match = re.search(r'(\d+)\s*report', text.lower())
                                                if count_match:
                                                    current_report["report_count"] = count_match.group(1)
                                                break
                                
                                # Don't forget the last report
                                if current_report is not None:
                                    reports.append(current_report)
    
    except Exception as e:
        logger.error(f"Error extracting GHS classifications: {e}")
    
    # Filter out empty reports
    reports = [r for r in reports if r.get("pictograms")]
    
    return reports

def extract_hazard_statements(ghs_data: dict) -> List[Dict[str, str]]:
    """Extract hazard statements from PubChem data"""
    statements = []
    seen_codes = set()
    try:
        sections = ghs_data.get("Record", {}).get("Section", [])
        for section in sections:
            if section.get("TOCHeading") == "Safety and Hazards":
                for subsection in section.get("Section", []):
                    if subsection.get("TOCHeading") == "Hazards Identification":
                        for subsubsection in subsection.get("Section", []):
                            if subsubsection.get("TOCHeading") == "GHS Classification":
                                for info in subsubsection.get("Information", []):
                                    if info.get("Name") == "GHS Hazard Statements":
                                        for markup in info.get("Value", {}).get("StringWithMarkup", []):
                                            text = markup.get("String", "")
                                            # Extract H-code
                                            h_match = re.search(r'(H\d{3})', text)
                                            if h_match:
                                                h_code = h_match.group(1)
                                                # Avoid duplicates
                                                if h_code not in seen_codes:
                                                    seen_codes.add(h_code)
                                                    zh_text = H_CODE_TRANSLATIONS.get(h_code, "")
                                                    statements.append({
                                                        "code": h_code,
                                                        "text_en": text,
                                                        "text_zh": zh_text if zh_text else text
                                                    })
    except Exception as e:
        logger.error(f"Error extracting hazard statements: {e}")
    return statements

def extract_signal_word(ghs_data: dict) -> tuple:
    """Extract signal word from PubChem data"""
    signal_translations = {
        "Danger": "å±éšª",
        "Warning": "è­¦å‘Š",
    }
    try:
        sections = ghs_data.get("Record", {}).get("Section", [])
        for section in sections:
            if section.get("TOCHeading") == "Safety and Hazards":
                for subsection in section.get("Section", []):
                    if subsection.get("TOCHeading") == "Hazards Identification":
                        for subsubsection in subsection.get("Section", []):
                            if subsubsection.get("TOCHeading") == "GHS Classification":
                                for info in subsubsection.get("Information", []):
                                    if info.get("Name") == "Signal":
                                        signal = info.get("Value", {}).get("StringWithMarkup", [{}])[0].get("String", "")
                                        return signal, signal_translations.get(signal, signal)
    except Exception as e:
        logger.error(f"Error extracting signal word: {e}")
    return None, None

def get_chinese_name_from_cas(cas_number: str) -> Optional[str]:
    """Get Chinese name directly from CAS number (most accurate method)"""
    if not cas_number:
        return None
    cas_normalized = cas_number.strip()
    
    # Direct CAS lookup - highest priority
    if cas_normalized in CAS_TO_ZH:
        return CAS_TO_ZH[cas_normalized]
    
    return None

def get_english_name_from_cas(cas_number: str) -> Optional[str]:
    """Get English name from CAS number via local dictionary"""
    if not cas_number:
        return None
    cas_normalized = cas_number.strip()
    
    # Direct lookup from CAS_TO_EN dictionary
    if cas_normalized in CAS_TO_EN:
        return CAS_TO_EN[cas_normalized]
    
    return None

def get_chinese_name_from_dict(name_en: str) -> Optional[str]:
    """Get Chinese name from English name dictionary"""
    if not name_en:
        return None
    name_lower = name_en.lower().strip()
    
    # Try expanded dictionary first (1816 entries)
    if name_lower in CHEMICAL_NAMES_ZH_EXPANDED:
        return CHEMICAL_NAMES_ZH_EXPANDED[name_lower]
    
    # Try legacy dictionary
    if name_lower in CHEMICAL_NAMES_ZH:
        return CHEMICAL_NAMES_ZH[name_lower]
    
    # Try partial match for compound names in expanded dict
    for en_name, zh_name in CHEMICAL_NAMES_ZH_EXPANDED.items():
        if en_name in name_lower or name_lower in en_name:
            return zh_name
    
    # Try partial match in legacy dict
    for en_name, zh_name in CHEMICAL_NAMES_ZH.items():
        if en_name in name_lower or name_lower in en_name:
            return zh_name
    
    # Try matching without special characters
    name_clean = re.sub(r'[^a-z0-9]', '', name_lower)
    for en_name, zh_name in CHEMICAL_NAMES_ZH_EXPANDED.items():
        en_clean = re.sub(r'[^a-z0-9]', '', en_name)
        if en_clean == name_clean or en_clean in name_clean or name_clean in en_clean:
            return zh_name
    
    return None

async def get_cid_from_cas(cas_number: str, http_client: httpx.AsyncClient) -> Optional[int]:
    """Get PubChem CID from CAS number - try multiple methods"""
    
    # Method 1: Search by CAS number as name
    try:
        url = f"https://pubchem.ncbi.nlm.nih.gov/rest/pug/compound/name/{cas_number}/cids/JSON"
        response = await http_client.get(url, timeout=15.0)
        if response.status_code == 200:
            data = response.json()
            cids = data.get("IdentifierList", {}).get("CID", [])
            if cids:
                return cids[0]
    except Exception as e:
        logger.debug(f"Method 1 failed for {cas_number}: {e}")
    
    # Method 2: Search via xref/rn endpoint (CAS Registry Number lookup)
    try:
        url = f"https://pubchem.ncbi.nlm.nih.gov/rest/pug/compound/xref/rn/{cas_number}/cids/JSON"
        response = await http_client.get(url, timeout=15.0)
        if response.status_code == 200:
            data = response.json()
            cids = data.get("IdentifierList", {}).get("CID", [])
            if cids:
                return cids[0]
    except Exception as e:
        logger.debug(f"Method 2 failed for {cas_number}: {e}")
    
    # Method 3: Search via substance xref (some compounds only have substance records)
    try:
        url = f"https://pubchem.ncbi.nlm.nih.gov/rest/pug/substance/xref/rn/{cas_number}/cids/JSON"
        response = await http_client.get(url, timeout=15.0)
        if response.status_code == 200:
            data = response.json()
            cids = data.get("InformationList", {}).get("Information", [])
            if cids and cids[0].get("CID"):
                return cids[0]["CID"][0] if isinstance(cids[0]["CID"], list) else cids[0]["CID"]
    except Exception as e:
        logger.debug(f"Method 3 failed for {cas_number}: {e}")
    
    # Method 4: Try with different CAS format (remove leading zeros)
    cas_alt = re.sub(r'^0+', '', cas_number.split('-')[0]) + '-' + '-'.join(cas_number.split('-')[1:])
    if cas_alt != cas_number:
        try:
            url = f"https://pubchem.ncbi.nlm.nih.gov/rest/pug/compound/name/{cas_alt}/cids/JSON"
            response = await http_client.get(url, timeout=15.0)
            if response.status_code == 200:
                data = response.json()
                cids = data.get("IdentifierList", {}).get("CID", [])
                if cids:
                    return cids[0]
        except Exception as e:
            logger.debug(f"Method 4 failed for {cas_number}: {e}")
    
    logger.warning(f"Could not find CID for CAS number: {cas_number}")
    return None

async def get_compound_name(cid: int, http_client: httpx.AsyncClient) -> tuple:
    """Get compound name in English and Chinese with multiple fallbacks"""
    name_en = None
    name_zh = None
    all_synonyms = []
    
    # Method 1: Get from property endpoint
    try:
        url = f"https://pubchem.ncbi.nlm.nih.gov/rest/pug/compound/cid/{cid}/property/IUPACName,Title/JSON"
        response = await http_client.get(url, timeout=15.0)
        if response.status_code == 200:
            data = response.json()
            props = data.get("PropertyTable", {}).get("Properties", [{}])[0]
            name_en = props.get("Title") or props.get("IUPACName")
    except Exception as e:
        logger.debug(f"Property endpoint failed for CID {cid}: {e}")
    
    # Method 2: Get from synonyms endpoint
    try:
        syn_url = f"https://pubchem.ncbi.nlm.nih.gov/rest/pug/compound/cid/{cid}/synonyms/JSON"
        syn_response = await http_client.get(syn_url, timeout=15.0)
        if syn_response.status_code == 200:
            syn_data = syn_response.json()
            all_synonyms = syn_data.get("InformationList", {}).get("Information", [{}])[0].get("Synonym", [])
            
            # If no name_en yet, use first synonym
            if not name_en and all_synonyms:
                name_en = all_synonyms[0]
            
            # Look for Chinese characters in synonyms
            for syn in all_synonyms:
                if any('\u4e00' <= char <= '\u9fff' for char in syn):
                    name_zh = syn
                    break
    except Exception as e:
        logger.debug(f"Synonyms endpoint failed for CID {cid}: {e}")
    
    # Method 3: Try description endpoint for name
    if not name_en:
        try:
            desc_url = f"https://pubchem.ncbi.nlm.nih.gov/rest/pug/compound/cid/{cid}/description/JSON"
            desc_response = await http_client.get(desc_url, timeout=15.0)
            if desc_response.status_code == 200:
                desc_data = desc_response.json()
                info_list = desc_data.get("InformationList", {}).get("Information", [])
                if info_list:
                    name_en = info_list[0].get("Title")
        except Exception as e:
            logger.debug(f"Description endpoint failed for CID {cid}: {e}")
    
    # If no Chinese name from PubChem, try local dictionary
    if not name_zh and name_en:
        name_zh = get_chinese_name_from_dict(name_en)
    
    # Try other synonyms in local dictionary
    if not name_zh:
        for syn in all_synonyms[:15]:  # Check first 15 synonyms
            zh = get_chinese_name_from_dict(syn)
            if zh:
                name_zh = zh
                break
    
    return name_en, name_zh

def extract_record_title(ghs_data: dict) -> str:
    """Extract RecordTitle from GHS data as fallback name"""
    try:
        return ghs_data.get("Record", {}).get("RecordTitle", "")
    except:
        return ""

def extract_iupac_name(ghs_data: dict) -> str:
    """Extract IUPAC name from GHS data as another fallback"""
    try:
        sections = ghs_data.get("Record", {}).get("Section", [])
        for section in sections:
            if section.get("TOCHeading") == "Names and Identifiers":
                for subsection in section.get("Section", []):
                    if subsection.get("TOCHeading") == "Computed Descriptors":
                        for subsubsection in subsection.get("Section", []):
                            if subsubsection.get("TOCHeading") == "IUPAC Name":
                                info = subsubsection.get("Information", [{}])[0]
                                return info.get("Value", {}).get("StringWithMarkup", [{}])[0].get("String", "")
    except:
        pass
    return ""

async def get_ghs_classification(cid: int, http_client: httpx.AsyncClient) -> dict:
    """Get GHS classification from PubChem"""
    try:
        url = f"https://pubchem.ncbi.nlm.nih.gov/rest/pug_view/data/compound/{cid}/JSON"
        response = await http_client.get(url, timeout=30.0)
        if response.status_code == 200:
            return response.json()
    except Exception as e:
        logger.error(f"Error getting GHS data for CID {cid}: {e}")
    return {}

async def search_chemical(cas_number: str, http_client: httpx.AsyncClient) -> ChemicalResult:
    """Search for a chemical by CAS number"""
    normalized_cas = normalize_cas(cas_number)
    
    if not normalized_cas:
        return ChemicalResult(
            cas_number=cas_number,
            found=False,
            error="ç„¡æ•ˆçš„ CAS è™Ÿç¢¼æ ¼å¼ï¼ˆæ­£ç¢ºæ ¼å¼å¦‚ï¼š64-17-5ï¼‰"
        )
    
    # Validate CAS number format (should be like XX-XX-X or XXXXX-XX-X)
    cas_pattern = re.match(r'^(\d{2,7})-(\d{2})-(\d)$', normalized_cas)
    if not cas_pattern:
        return ChemicalResult(
            cas_number=cas_number,
            found=False,
            error=f"CAS è™Ÿç¢¼æ ¼å¼ä¸æ­£ç¢ºï¼š{normalized_cas}ï¼ˆæ­£ç¢ºæ ¼å¼å¦‚ï¼š64-17-5ï¼‰"
        )
    
    # ===== NEW: Try to get Chinese and English name from CAS dictionary FIRST (most accurate) =====
    name_zh_from_cas = get_chinese_name_from_cas(normalized_cas)
    name_en_from_cas = get_english_name_from_cas(normalized_cas)
    if name_zh_from_cas:
        logger.info(f"Found Chinese name from CAS dictionary for {normalized_cas}: {name_zh_from_cas}")
    if name_en_from_cas:
        logger.info(f"Found English name from CAS dictionary for {normalized_cas}: {name_en_from_cas}")
    
    # Get CID - try multiple methods
    cid = await get_cid_from_cas(normalized_cas, http_client)
    if not cid:
        # Even if PubChem doesn't have CID, we might have local data
        if name_zh_from_cas or name_en_from_cas:
            return ChemicalResult(
                cas_number=cas_number,
                cid=None,
                name_en=name_en_from_cas,  # Provide English name from local dictionary
                name_zh=name_zh_from_cas,
                ghs_pictograms=[],
                hazard_statements=[],
                signal_word=None,
                signal_word_zh=None,
                found=True,
                error="PubChem ç„¡ GHS è³‡æ–™ï¼Œåƒ…æä¾›æœ¬åœ°å­—å…¸åç¨±"
            )
        # Provide more helpful error message
        return ChemicalResult(
            cas_number=cas_number,
            found=False,
            error=f"åœ¨ PubChem è³‡æ–™åº«ä¸­æ‰¾ä¸åˆ° CAS {normalized_cas}ï¼Œè«‹ç¢ºèªè™Ÿç¢¼æ˜¯å¦æ­£ç¢º"
        )
    
    # Get compound name and GHS data concurrently
    name_task = get_compound_name(cid, http_client)
    ghs_task = get_ghs_classification(cid, http_client)
    
    (name_en, name_zh), ghs_data = await asyncio.gather(name_task, ghs_task)
    
    # Extract ALL GHS classification reports
    all_classifications = extract_all_ghs_classifications(ghs_data)
    
    # Separate primary (first) classification from others
    primary_pictograms = []
    primary_hazards = []
    primary_signal = None
    primary_signal_zh = None
    other_classifications = []
    
    if all_classifications:
        # First report is the primary classification
        primary = all_classifications[0]
        primary_pictograms = primary.get("pictograms", [])
        primary_hazards = primary.get("hazard_statements", [])
        primary_signal = primary.get("signal_word")
        primary_signal_zh = primary.get("signal_word_zh")
        
        # Rest are other classifications (deduplicate by pictogram set)
        seen_pictogram_sets = set()
        primary_pic_set = frozenset(p["code"] for p in primary_pictograms)
        seen_pictogram_sets.add(primary_pic_set)
        
        for report in all_classifications[1:]:
            pic_set = frozenset(p["code"] for p in report.get("pictograms", []))
            if pic_set and pic_set not in seen_pictogram_sets:
                seen_pictogram_sets.add(pic_set)
                other_classifications.append(GHSReport(
                    pictograms=report.get("pictograms", []),
                    hazard_statements=report.get("hazard_statements", []),
                    signal_word=report.get("signal_word"),
                    signal_word_zh=report.get("signal_word_zh"),
                    source=report.get("source"),
                    report_count=report.get("report_count")
                ))
    
    # Use RecordTitle as fallback for name_en if not found
    if not name_en:
        name_en = extract_record_title(ghs_data)
    
    # Try IUPAC name as another fallback
    if not name_en:
        name_en = extract_iupac_name(ghs_data)
    
    # If still no name, use CAS number as name
    if not name_en:
        name_en = f"CID-{cid}"
        logger.warning(f"No name found for CAS {cas_number}, using CID as fallback")
    
    # ===== OPTIMIZED Chinese name lookup order =====
    # Priority 1: CAS dictionary (most accurate - from user's Excel)
    if name_zh_from_cas:
        name_zh = name_zh_from_cas
    # Priority 2: PubChem Chinese synonyms (already fetched)
    elif name_zh:
        pass  # Keep PubChem result
    # Priority 3: English name dictionary lookup
    else:
        name_zh = get_chinese_name_from_dict(name_en)
    
    return ChemicalResult(
        cas_number=cas_number,
        cid=cid,
        name_en=name_en,
        name_zh=name_zh,
        ghs_pictograms=primary_pictograms,
        hazard_statements=primary_hazards,
        signal_word=primary_signal,
        signal_word_zh=primary_signal_zh,
        other_classifications=other_classifications,
        has_multiple_classifications=len(other_classifications) > 0,
        found=True
    )

# API Routes
@api_router.get("/")
async def root():
    return {"message": "GHS Label Quick Search API"}

@api_router.post("/search", response_model=List[ChemicalResult])
async def search_chemicals(query: CASQuery):
    """Search for chemicals by CAS numbers"""
    results = []
    async with httpx.AsyncClient() as http_client:
        # Process in batches to avoid overwhelming the API
        batch_size = 5
        for i in range(0, len(query.cas_numbers), batch_size):
            batch = query.cas_numbers[i:i+batch_size]
            tasks = [search_chemical(cas, http_client) for cas in batch]
            batch_results = await asyncio.gather(*tasks)
            results.extend(batch_results)
            # Add small delay between batches
            if i + batch_size < len(query.cas_numbers):
                await asyncio.sleep(0.5)
    return results

@api_router.get("/search/{cas_number}", response_model=ChemicalResult)
async def search_single_chemical(cas_number: str):
    """Search for a single chemical by CAS number"""
    async with httpx.AsyncClient() as http_client:
        return await search_chemical(cas_number, http_client)

@api_router.post("/export/xlsx")
async def export_xlsx(request: ExportRequest):
    """Export results to Excel file"""
    wb = Workbook()
    ws = wb.active
    ws.title = "GHSæŸ¥è©¢çµæžœ"
    
    # Header style
    header_font = Font(bold=True, color="FFFFFF")
    header_fill = PatternFill(start_color="4472C4", end_color="4472C4", fill_type="solid")
    header_alignment = Alignment(horizontal="center", vertical="center", wrap_text=True)
    thin_border = Border(
        left=Side(style='thin'),
        right=Side(style='thin'),
        top=Side(style='thin'),
        bottom=Side(style='thin')
    )
    
    # Headers
    headers = ["CAS No.", "è‹±æ–‡åç¨±", "ä¸­æ–‡åç¨±", "GHSæ¨™ç¤º", "è­¦ç¤ºèªž", "å±å®³èªªæ˜Ž"]
    for col, header in enumerate(headers, 1):
        cell = ws.cell(row=1, column=col, value=header)
        cell.font = header_font
        cell.fill = header_fill
        cell.alignment = header_alignment
        cell.border = thin_border
    
    # Data
    for row, result in enumerate(request.results, 2):
        ws.cell(row=row, column=1, value=result.get("cas_number", "")).border = thin_border
        ws.cell(row=row, column=2, value=result.get("name_en", "")).border = thin_border
        ws.cell(row=row, column=3, value=result.get("name_zh", "")).border = thin_border
        
        # GHS pictograms
        pictograms = result.get("ghs_pictograms", [])
        ghs_text = ", ".join([f"{p.get('code', '')} ({p.get('name_zh', '')})" for p in pictograms]) if pictograms else "ç„¡"
        ws.cell(row=row, column=4, value=ghs_text).border = thin_border
        
        # Signal word
        signal = result.get("signal_word_zh") or result.get("signal_word") or "-"
        ws.cell(row=row, column=5, value=signal).border = thin_border
        
        # Hazard statements
        statements = result.get("hazard_statements", [])
        hazard_text = "\n".join([f"{s.get('code', '')}: {s.get('text_zh', '')}" for s in statements]) if statements else "ç„¡å±å®³èªªæ˜Ž"
        cell = ws.cell(row=row, column=6, value=hazard_text)
        cell.border = thin_border
        cell.alignment = Alignment(wrap_text=True)
    
    # Adjust column widths
    ws.column_dimensions['A'].width = 15
    ws.column_dimensions['B'].width = 30
    ws.column_dimensions['C'].width = 20
    ws.column_dimensions['D'].width = 35
    ws.column_dimensions['E'].width = 12
    ws.column_dimensions['F'].width = 50
    
    # Save to BytesIO
    output = BytesIO()
    wb.save(output)
    output.seek(0)
    
    return StreamingResponse(
        output,
        media_type="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        headers={"Content-Disposition": "attachment; filename=ghs_results.xlsx"}
    )

@api_router.post("/export/csv")
async def export_csv(request: ExportRequest):
    """Export results to CSV file"""
    output = BytesIO()
    # Add BOM for Excel compatibility with Chinese characters
    output.write(b'\xef\xbb\xbf')
    
    # Write CSV
    writer = csv.writer(output.getvalue().decode('utf-8-sig').splitlines() if False else output, delimiter=',')
    
    # Use StringIO for proper CSV writing
    from io import StringIO
    string_output = StringIO()
    writer = csv.writer(string_output)
    
    # Headers
    writer.writerow(["CAS No.", "è‹±æ–‡åç¨±", "ä¸­æ–‡åç¨±", "GHSæ¨™ç¤º", "è­¦ç¤ºèªž", "å±å®³èªªæ˜Ž"])
    
    # Data
    for result in request.results:
        pictograms = result.get("ghs_pictograms", [])
        ghs_text = ", ".join([f"{p.get('code', '')} ({p.get('name_zh', '')})" for p in pictograms]) if pictograms else "ç„¡"
        
        signal = result.get("signal_word_zh") or result.get("signal_word") or "-"
        
        statements = result.get("hazard_statements", [])
        hazard_text = "; ".join([f"{s.get('code', '')}: {s.get('text_zh', '')}" for s in statements]) if statements else "ç„¡å±å®³èªªæ˜Ž"
        
        writer.writerow([
            result.get("cas_number", ""),
            result.get("name_en", ""),
            result.get("name_zh", ""),
            ghs_text,
            signal,
            hazard_text
        ])
    
    # Convert to bytes with BOM
    csv_content = string_output.getvalue()
    output = BytesIO()
    output.write(b'\xef\xbb\xbf')  # BOM
    output.write(csv_content.encode('utf-8'))
    output.seek(0)
    
    return StreamingResponse(
        output,
        media_type="text/csv; charset=utf-8",
        headers={"Content-Disposition": "attachment; filename=ghs_results.csv"}
    )

@api_router.get("/ghs-pictograms")
async def get_ghs_pictograms():
    """Get all GHS pictogram information"""
    return GHS_PICTOGRAMS

# Include the router in the main app
app.include_router(api_router)

app.add_middleware(
    CORSMiddleware,
    allow_credentials=True,
    allow_origins=os.environ.get('CORS_ORIGINS', '*').split(','),
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.on_event("shutdown")
async def shutdown_db_client():
    if client:
        client.close()
